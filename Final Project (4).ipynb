{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b77167-911c-48e2-9f1d-9fae4e4cfe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f37422-abab-4f22-aceb-52db49de4780",
   "metadata": {},
   "source": [
    "# Download & Clean Each Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fbe000-78ec-4915-9171-ee14c0758bf7",
   "metadata": {},
   "source": [
    "We have 3 different data sets that we are using for the project.\n",
    "1. Coffee Quality Data\n",
    "- From the Coffee Quality Data we extracted the Country Name, No. of Bags, Harvest Year and Bag Weight.\n",
    "2. Meat Production Data\n",
    "- From the Meat Dataset we focused on analyzing Country, Year, and Production in tonns\n",
    "3. CO2 Emmisions\n",
    "- From the CO2 Emmisions dataset we focused on the Country, Year, and the CO2 Emissions in kiloton (kt)\n",
    "4. Milk Production Dataset\n",
    "- From the Milk Production Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db562986-b1d2-40f0-a782-59718e43572a",
   "metadata": {},
   "source": [
    "## Coffee Quality Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051d1343-c600-42a8-8ae8-d797e1640652",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = os.getcwd()\n",
    "\n",
    "# Construct the full path to the CSV file\n",
    "file_path = os.path.join(project_dir, 'coffee.csv')\n",
    "\n",
    "# Read the CSV file\n",
    "coffee_df = pd.read_csv(file_path)\n",
    "\n",
    "#CLEANING UP THE DATA (getting rid of unneccessary info ie. columns)\n",
    "dimensions = coffee_df.shape\n",
    "print(\"Dimensions before Cleaning:\", dimensions)\n",
    "print(coffee_df.head(6))\n",
    "\n",
    "coffee_df = coffee_df[[\"Country of Origin\", \"Number of Bags\", \"Bag Weight\", \"Harvest Year\"]]#Taking only the columns we need\n",
    "\n",
    "dimensions = coffee_df.shape\n",
    "print(\"\\nDimensions after Cleaning:\",dimensions)\n",
    "print(coffee_df.head(6))\n",
    "\n",
    "#May want to drop all the columns except the country name, no. of bags, harvest year and bag weight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a152328b-dca7-4fde-b84c-4109ab0a1657",
   "metadata": {},
   "source": [
    "### Null/Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993f0748-668f-4ef4-8a98-8a70f4c3b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Missing Values\n",
    "#Column 1\n",
    "missing_countries = coffee_df[\"Country of Origin\"].isnull().sum()\n",
    "print(\"Amount of Missing Values for Column 1:\", missing_countries)\n",
    "\n",
    "#Column 2\n",
    "missing_bags = coffee_df[\"Number of Bags\"].isnull().sum()\n",
    "print(\"Amount of Missing Values for Column 2:\", missing_bags)\n",
    "\n",
    "#Column 3\n",
    "missing_weight = coffee_df[\"Bag Weight\"].isnull().sum()\n",
    "print(\"Amount of Missing Values for Column 3:\", missing_weight)\n",
    "\n",
    "#Column 4\n",
    "missing_year = coffee_df[\"Harvest Year\"].isnull().sum()\n",
    "print(\"Amount of Missing Values for Column 4:\", missing_year)\n",
    "\n",
    "#Finding Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7462579-fe7e-4910-88e6-aa117f102239",
   "metadata": {},
   "source": [
    "## Meat Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299a6d61-8e4f-4d44-8edf-e0065518f5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = os.getcwd()\n",
    "\n",
    "# Construct the full path to the CSV file\n",
    "file_path = os.path.join(project_dir, 'meat.csv')\n",
    "meat_df = pd.read_csv(file_path)\n",
    "#df = pd.read_csv('/home/ssg145/final/meat.csv')\n",
    "initial_size = meat_df.shape[0]\n",
    "\n",
    "dimensions = meat_df.shape\n",
    "print(\"Dimensions before Cleaning:\", dimensions)\n",
    "print(meat_df.head(6))\n",
    "\n",
    "#CLEANING UP DATA\n",
    "meat_df = meat_df.drop(columns=['Code'])\n",
    "#print(df.head(6))\n",
    "\n",
    "meat_df = meat_df.rename(columns={'Meat, total | 00001765 || Production | 005510 || tonnes': 'Production amt'})\n",
    "\n",
    "dimensions = meat_df.shape\n",
    "print(\"\\nDimensions after Cleaning:\", dimensions)\n",
    "print(meat_df.head(6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef0a8a8-aec5-4ed7-a649-e1040dc2fcad",
   "metadata": {},
   "source": [
    "### Null/Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3f46e0-297e-4277-abdc-4ef4f6306871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Missing Values\n",
    "#Column 1\n",
    "missing_countries = meat_df[\"Country\"].isnull().sum()\n",
    "print(\"Amount of Missing Values for Column 1:\", missing_countries)\n",
    "\n",
    "#Column 2\n",
    "missing_year = meat_df[\"Year\"].isnull().sum()\n",
    "print(\"Amount of Missing Values for Column 2:\", missing_year)\n",
    "\n",
    "#Column 3\n",
    "missing_production = meat_df[\"Production amt\"].isnull().sum()\n",
    "print(\"Amount of Missing Values for Column 3:\", missing_production)\n",
    "\n",
    "#Finding Null Values: there are country values that are continents or low income/high income countries\n",
    "print(meat_df.shape)\n",
    "bad_values = [\"Asia\", \"North America\", \"Africa\", \"South America\", \"Europe\", \"Antartica\", \"World\", \"Lower-middle-income countries\", \"Upper-middle-income countries\", \"High-income countries\", \"Low-income countries\"]\n",
    "meat_df = meat_df[~meat_df[\"Country\"].str.contains(\"|\".join(bad_values), case = False, na = False)]\n",
    "print(meat_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3965f73-2bbd-4527-aba1-74b9f787bd49",
   "metadata": {},
   "source": [
    "## CO2 Emmissions Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ae1e47-c866-45c0-b718-beaa4895d5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('./final/co2_country.csv')\n",
    "project_dir = os.getcwd()\n",
    "\n",
    "# Construct the full path to the CSV file\n",
    "file_path = os.path.join(project_dir, 'co2_country.csv')\n",
    "df_co2 = pd.read_csv(file_path)\n",
    "\n",
    "dimensions = df_co2.shape\n",
    "print(\"Dimensions before Cleaning:\", dimensions)\n",
    "print(df_co2.head(6))\n",
    "\n",
    "#Clean the data (get rid of the country codes)\n",
    "df_co2 = df_co2.iloc[:, 1:]\n",
    "\n",
    "dimensions = df_co2.shape\n",
    "print(\"\\nDimensions before Cleaning:\", dimensions)\n",
    "print(df_co2.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc9fc29-5a67-43d9-8b8e-077848442276",
   "metadata": {},
   "source": [
    "### Null/Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b763684-b698-45ed-9bbe-c18bc88c515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Missing Values\n",
    "#Column 1\n",
    "missing_countries = df_co2[\"country_name\"].isnull().sum()\n",
    "print(\"Amount of Missing Values for Column 1:\", missing_countries)\n",
    "\n",
    "#Column 2\n",
    "missing_year = df_co2[\"year\"].isnull().sum()\n",
    "print(\"Amount of Missing Values for Column 2:\", missing_year)\n",
    "\n",
    "#Column 3\n",
    "missing_value = df_co2[\"value\"].isnull().sum()\n",
    "print(\"Amount of Missing Values for Column 3:\", missing_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983363b5-1bfb-4f0c-b168-658be07006cb",
   "metadata": {},
   "source": [
    "## Milk Production Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1c4446-5cba-472e-bc43-618e246a32bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = os.getcwd()\n",
    "\n",
    "# Construct the full path to the CSV file\n",
    "file_path = os.path.join(project_dir, 'milk.csv')\n",
    "milk_df = pd.read_csv(file_path)\n",
    "#df = pd.read_csv('/home/ssg145/final/meat.csv')\n",
    "initial_size = milk_df.shape[0]\n",
    "\n",
    "#print(df.head(6))\n",
    "\n",
    "#CLEANING UP DATA\n",
    "dimensions = milk_df.shape\n",
    "print(\"Dimensions before Cleaning:\", dimensions)\n",
    "print(milk_df.head(6))\n",
    "milk_df = milk_df.drop(columns=['Code'])\n",
    "\n",
    "milk_df = milk_df.rename(columns={'Milk | 00001780 || Production | 005510 || tonnes': 'Milk amt'})\n",
    "milk_df = milk_df.rename(columns={'Entity': 'Country'})\n",
    "\n",
    "dimensions = milk_df.shape\n",
    "print(\"\\nDimensions after Cleaning:\", dimensions)\n",
    "print(milk_df.head(6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f51a3-d2cf-4bb9-bf43-362cc716b2f6",
   "metadata": {},
   "source": [
    "### Null/Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d096de-1c4c-46ae-a0e8-f6958f0ba219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Missing Values\n",
    "#Column 1\n",
    "missing_countries = milk_df[\"Country\"].isnull().sum()\n",
    "print(\"Amount of Missing Values for Column 1:\", missing_countries)\n",
    "\n",
    "#Column 2\n",
    "missing_year = milk_df[\"Year\"].isnull().sum()\n",
    "print(\"Amount of Missing Values for Column 2:\", missing_year)\n",
    "\n",
    "#Column 3\n",
    "missing_value = milk_df[\"Milk amt\"].isnull().sum()\n",
    "print(\"Amount of Missing Values for Column 3:\", missing_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e8c614-ad9a-4b53-9444-c872d678a553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Steps \n",
    "#Check for null/missing values \n",
    "#average the country values \n",
    "#join the datasets \n",
    "#Perform analysis (linear regression) \n",
    "#Create a prediction model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b9debb-4baa-4429-bce7-7d7a8499b0ac",
   "metadata": {},
   "source": [
    "### Average Country Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ed765a-11ac-467c-b1f7-422297c0d75b",
   "metadata": {},
   "source": [
    "### Join Datasets Using SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd5df2e-cd40-4930-b35c-34fcb2fa5b9d",
   "metadata": {},
   "source": [
    "### Perform Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3696a7-dd42-4c72-bffe-169e24190ba8",
   "metadata": {},
   "source": [
    "### Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793cdff6-1b80-408f-b4d7-2c450011b5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
